{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "39UkRK5z08xB"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1nUO72t2Ym_"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('https://github.com/tknishh/Text-Classification-Ag-News/raw/master/data/train.csv')\n",
        "train = train.sample(len(train))\n",
        "test = pd.read_csv('https://github.com/tknishh/Text-Classification-Ag-News/raw/master/data/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1GAAhrtXHZr"
      },
      "source": [
        "# Categorias\n",
        "* World\n",
        "* Sports\n",
        "* Business\n",
        "* Science/Technology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxtS8T0CWpNJ",
        "outputId": "bd5da0ce-dbf5-4cbf-a9b6-9aa3f5c87232"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13497     Khatami says IAEA must accept Iran #39;s right...\n",
              "110891           Annan gets ovation at UN despite US attack\n",
              "97892                   Bush Has a Plan to Create Jobs (AP)\n",
              "105526       American Military Relief Effort Picks Up Steam\n",
              "15392                 Thatcher #39;s wife lands at Heathrow\n",
              "47798              Amy Fisher Addresses Her Past in New Bio\n",
              "45901                          Blair to stay for third term\n",
              "12315             Convention Protesters Eager to Begin (AP)\n",
              "116179    Turkish captain foils EU #39;s would-be defenders\n",
              "90653             Thai PM weighs call for conciliatory body\n",
              "Name: Title, dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[train['Class Index'] == 1].sample(10)['Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS4_iiADW96w",
        "outputId": "3ad2c070-080d-4b98-83ff-0116ff2a0ba3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48890                  Garciaparra still interested in Cubs\n",
              "11819         Schumacher tipped to win seventh championship\n",
              "93144           Hawks Rally From 11 Down, Edge Rockets (AP)\n",
              "45776     Schwarzenegger Vetoes Sports Diet Supplement Bill\n",
              "32634            NFL Game Summary - Carolina at Kansas City\n",
              "5093                             Pakistan to rest speed duo\n",
              "74196                              Peace summit to end feud\n",
              "115889                                        Senor Moment?\n",
              "66154     Red Sox Look to Reverse the Curse with Game Se...\n",
              "98492                  ROVERS BOUNCE BACK IN EWOOD THRILLER\n",
              "Name: Title, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[train['Class Index'] == 2].sample(10)['Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gPuo2zdXAOy",
        "outputId": "49f491ef-23b6-4f4e-93c2-56d24407cbad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "101239       Shortage of steel forces halt at Nissan\n",
              "12562          Oil prices firm after week of decline\n",
              "64525                   House prices go on the slide\n",
              "105487                        Gold Offer Loses Shine\n",
              "110953    SEC probes auditor's link to fund trustees\n",
              "54681            Krispy Kreme #39;s Sticky Situation\n",
              "3735               Qantas posts record annual profit\n",
              "89522                             The Toy War Begins\n",
              "119202       Bad Day for Drug Companies and Patients\n",
              "67697                        Merger wounds JP Morgan\n",
              "Name: Title, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[train['Class Index'] == 3].sample(10)['Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yKjRewzXDBb",
        "outputId": "bd5846a5-802e-427b-9491-02f9469430f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33314    PeopleSoft prepares for questions at Connect show\n",
              "3717           Bankrupt Commerce One Patents Fetch \\$15.5M\n",
              "68500        Colo. bird population reported in sorry state\n",
              "48825    Mount Vernon City Library to close books on ru...\n",
              "73581         Intel eyes remote wireless device management\n",
              "90676        Opportunity Rover to Pack Up and Leave Crater\n",
              "28822    Inventor Develops Nose-Steered Web Surfing Sys...\n",
              "51609                       Web Industry Still Flies Blind\n",
              "1509     HP releases  quot;carrier quot; grade Linux fo...\n",
              "9389             Actuate pushes open-source data reporting\n",
              "Name: Title, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[train['Class Index'] == 4].sample(10)['Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvgytPCze5Yg"
      },
      "outputs": [],
      "source": [
        "train['content'] = train['Title'] + \" \" + train['Description']\n",
        "test['content'] = test['Title'] + \" \" + test['Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKhq6tK19EDC"
      },
      "source": [
        "# Cargo embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cc_zOScn2bI9",
        "outputId": "4b9f19b9-5818-4b83-d553-4b007596e3fa"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m downloader\n\u001b[0;32m      4\u001b[0m downloader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGoogleNews-vectors-negative300.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Facu\\anaconda3\\envs\\NLP\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Facu\\anaconda3\\envs\\NLP\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2045\u001b[0m             counts[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(count)\n\u001b[0;32m   2047\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n\u001b[1;32m-> 2048\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[0;32m   2050\u001b[0m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
            "File \u001b[1;32mc:\\Users\\Facu\\anaconda3\\envs\\NLP\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
            "File \u001b[1;32mc:\\Users\\Facu\\anaconda3\\envs\\NLP\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim import downloader\n",
        "\n",
        "model = downloader.load('word2vec-google-news-300')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHbtosSSLE7X"
      },
      "source": [
        "Nos quedamos solo con las palabras útiles en un set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2d4SuDELC-A"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "TOKENIZER_REGEX = r\"\\w+(?:'\\w+)?|[^\\w\\s]\"\n",
        "\n",
        "palabras_utiles = set()\n",
        "\n",
        "for text in train['content'].tolist():\n",
        "  palabras_utiles.update(re.findall(TOKENIZER_REGEX, text.lower()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDyBUI58LbYl"
      },
      "outputs": [],
      "source": [
        "len(palabras_utiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3KJ4_1UAcYM"
      },
      "source": [
        "Extraemos los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tiOQDlsAY84"
      },
      "outputs": [],
      "source": [
        "key_to_index = {}\n",
        "embs = []\n",
        "\n",
        "for i in range(len(model)):\n",
        "  # Para ahorrar RAM, solo nos quedamos con el vector si es parte de las palabras utiles\n",
        "  if model.index_to_key[i] in palabras_utiles:\n",
        "    key_to_index[model.index_to_key[i]] = len(embs)\n",
        "    embs.append(model[model.index_to_key[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXTUp-DaA5zP"
      },
      "outputs": [],
      "source": [
        "embs = np.asarray(embs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fYAZTojBCC0"
      },
      "outputs": [],
      "source": [
        "embs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhWJ76G3BuEj"
      },
      "outputs": [],
      "source": [
        "#ahorramos ram\n",
        "model = None\n",
        "palabras_utiles = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4B8mem9A3Gq"
      },
      "source": [
        "Creamos un vector para la palabra deconocida usando el promedio de todas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcYnj7YNA93J"
      },
      "outputs": [],
      "source": [
        "unknown_emb = embs.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mboahOeVBAhH"
      },
      "outputs": [],
      "source": [
        "unknown_emb.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozpqr06_BGV8"
      },
      "source": [
        "Creamos la matriz de embeddings, en el indice 0 contiene a un vector de 0s para indicar que no hay palabras, en el indice 1 contiene al vector de palabra desconocida y en el resto las palabras del embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkYqR4wiBBj9"
      },
      "outputs": [],
      "source": [
        "embs = np.concatenate([np.zeros((1,300)), unknown_emb.reshape((1,300)), embs], axis=0)\n",
        "embs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuFQfUdXABS3"
      },
      "source": [
        "Tokenizamos todos los textos y transformamos cada palabra en índice de la matriz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdXG6cVzAFGv"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "\n",
        "for text in train['content'].tolist():\n",
        "  tokens = re.findall(TOKENIZER_REGEX, text.lower())\n",
        "  # Sumamos 2 por el vector de 0s y el de unknown\n",
        "  tokens = [key_to_index[t] + 2 if t in key_to_index else 1 for t in tokens]\n",
        "  X_train.append(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qnbHxdsATuZ"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "\n",
        "for text in test['content'].tolist():\n",
        "  tokens = re.findall(TOKENIZER_REGEX, text.lower())\n",
        "  # Sumamos 2 por el vector de 0s y el de unknown\n",
        "  tokens = [key_to_index[t] + 2 if t in key_to_index else 1 for t in tokens]\n",
        "  X_test.append(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqSTL2e2BZwr"
      },
      "outputs": [],
      "source": [
        "print(train['content'].tolist()[0])\n",
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCWdP5XvDHTL"
      },
      "source": [
        "Paddeamos los textos para que tengan todos el mismo largo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxZHb49CDYL7"
      },
      "outputs": [],
      "source": [
        "np.quantile([len(x) for x in X_train], 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-wVTUMTDNfv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOEnUNvcH5SW"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train,maxlen=55,padding='post',truncating='post',value=0)\n",
        "X_test = pad_sequences(X_test,maxlen=55,padding='post',truncating='post',value=0)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIQlJVqFJR0o"
      },
      "outputs": [],
      "source": [
        "y_train = train['Class Index'].values.reshape((-1, 1))-1\n",
        "y_test = test['Class Index'].values.reshape((-1, 1))-1\n",
        "\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlkj6B26CXoT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv1D, GlobalMaxPooling1D, GRU, Concatenate, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr7CXMgKDF93"
      },
      "outputs": [],
      "source": [
        "inp = Input((55,), dtype='int32')\n",
        "# Ponemos que los embeddings no sean entrenables\n",
        "emb_layer = Embedding(input_dim=embs.shape[0], output_dim=embs.shape[1], weights=[embs], trainable=False)(inp)\n",
        "conv1 = Conv1D(16, kernel_size=2, padding='same')(emb_layer)\n",
        "conv2 = Conv1D(8, kernel_size=3, padding='same')(emb_layer)\n",
        "conv3 = Conv1D(4, kernel_size=5, padding='same')(emb_layer)\n",
        "concat = Concatenate()([conv1, conv2, conv3])\n",
        "maxpool = GlobalMaxPooling1D()(concat)\n",
        "out = Dense(4, activation='softmax')(maxpool)\n",
        "model = Model(inputs=inp, outputs=out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ftWga0CJhJ7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ERTt9bsKMS8"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.1, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75_0i_yBNT8X"
      },
      "outputs": [],
      "source": [
        "preds = np.argmax(model.predict(X_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rvs9wPiQEoz"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG8Ic8RGQKt_"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay(confusion_matrix(y_test, preds)).plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
