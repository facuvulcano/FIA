{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "Norvig capítulo 18\n",
    "Otra estrellita para este ejercicio\n",
    "\n",
    "Indicar cuáles de las siguientes opciones son correctas:\n",
    "\n",
    "1. Si el modelo que usamos es muy complejo para nuestros datos podemos tener un problema de underfitting.\n",
    "    \n",
    "    - Respuesta: Falso, si utilizamos un modelo muy complejo lo que sucedera es que el modelo aprendera con mucha precision los datos de entrenamiento lo que generara una funcion que siga muy precisamente todos esos datos, como si se los aprendier a todos de memoria. Si graficamos se veria una curva que pasa por todos los datos de entrenamiento. El problema de este modelo es que cuando aparece un nuevo dato que no conoce, podria tener una prediccion equivocada del output ya que el modelo no esta bien preparado para manejar cosas que no conoce. Entonces, en el caso de un modelo muy complejo lo que tendriamos es un problema de overfitting.\n",
    "\n",
    "2. En KNN cuando k es muy bajo podemos underfittear. \n",
    "\n",
    "    - Respuesta: Falso, un k muy chico probablemente overfitte, si K = N tenemos un problema de underfitting porque siempre vamos a obtener el mismo resultado.\n",
    "\n",
    "3. Aplicar un filtro convolucional de 1x1 nos devuelve un output de igual dimensiones quew el input.\n",
    "\n",
    "    - Respuesta: Verdadero, esto es correcto ya que ira pixel por pixel para todos los pixels de la imagen. \n",
    "\n",
    "4. Para un modelo de Gradient Boosting o Random Forest no tiene sentido normalizar las columnas del dataset.\n",
    "\n",
    "    - Respuesta: Verdadero\n",
    "\n",
    "5. Para un modelo basado en árboles es buena idea agregar features que representen relaciones entre otras\n",
    "columnas, por ejemplo ratios.\n",
    "\n",
    "    - Respuesta: Verdadero, esto me agregara mas informacion. Aparte es infomracion que no se puede generar sola como en una red neuronal. Esto es feature engineering.\n",
    "\n",
    "6. Mediante cross-validation podemos reducir el overfitting.\n",
    "\n",
    "    - Verdadero: Ya que podemos probar combinaciones de testing y training distintas.\n",
    "\n",
    "7. La búsqueda de hiper-parámetros en un random-forest es menos importante que en XGBoost.\n",
    "\n",
    "    - Verdadero, ya que XGBoost es como una optimizacion del random-forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de evaluación\n",
    "\n",
    "Dada la siguiente tabla que muestra los resultados de un determinado modelo de clasificación binaria aplicados a\n",
    "un set de test:\n",
    "\n",
    "Registro Label Predicción\n",
    "    A      1        1               TP\n",
    "    B      1        0               FN\n",
    "    C      0        0               TN\n",
    "    D      0        0               TN\n",
    "    E      0        0               TN\n",
    "    F      1        1               TP\n",
    "    G      1        1               TP\n",
    "    H      0        1               FP\n",
    "\n",
    "Calcular las siguientes métricas:\n",
    "\n",
    "1. Accuracy.\n",
    "2. Tasa de Falsos Negativos.\n",
    "3. Tasa de Falsos Positivos.\n",
    "4. Recall.\n",
    "5. Precision.\n",
    "\n",
    "\n",
    "- Accuracy (cuantas de las predicciones acerte): (TP + TN) / (TP + TN + FN + FP) ---> Correct predictions / all predictions\n",
    "Cuando los datos estan muy desbalanceados podemos tener un accuracy muy malo, necesita que la catnidad de 1 y 0 sea pareja.\n",
    "\n",
    "- Recall = TP / (TP + FN)\n",
    "\n",
    "- Precision = TP / (TP + FP) de cuando yo digo que algo es positivo que probabilidad hay de que sea positivo\n",
    "\n",
    "\n",
    "Respuestas:\n",
    "\n",
    "1- Accuracy: 6 / 8 = 0.75 --> 75%\n",
    "\n",
    "2- FN / (FN + TP) = 1 / 4 = 0.25 --> 25%\n",
    "\n",
    "3- FP / (FP + TN) = 1 / 4 = 0.25 --> 25%\n",
    "\n",
    "4- RECALL = 3 / 6 = 0.5 --> 50%\n",
    "\n",
    "5- PRECISION = 3 / 4 =  0.75 --> 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbolito\n",
    "\n",
    "A partir del siguiente set de entrenamiento para el problema de predecir si a una persona le va a gustar o no una\n",
    "película:\n",
    "\n",
    "Person isAmerican? isActionMovie? Likes?\n",
    "  A        Y            N           Y\n",
    "  B        N            Y           Y\n",
    "  C        Y            Y           N  \n",
    "  D        Y            N           Y\n",
    "  E        Y            N           Y\n",
    "  F        N            Y           Y\n",
    "  G        Y            Y           N\n",
    "  H        N            N           N\n",
    "\n",
    "  Construir el mejor árbol de decisión posible.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
