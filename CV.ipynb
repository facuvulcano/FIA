{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de imagenes\n",
    "\n",
    "Idea es procesar imagenes, para nosotros una imagen va a ser en w * h  * 3\n",
    "\n",
    "w = width\n",
    "h = height\n",
    "3 = los tres canales del color (RGB)\n",
    "\n",
    "Tipo de problemas que podemos tener:\n",
    "\n",
    "- Clasificacion: tenemos una imagen y queremos decir a que clase pertenece. Para clasificacion los datasets mas populares son Mnist (son datasets de deteccion de digitos manuscritos, generalmente del 1 al 9, 50.000 imagenes, 10 clases (10 digitos posibles)), Cifar (60.000 imagenes de 32 x 32 en 10 clases de deteccion de objetos de imagenes a color), ImageNet (20.000 clases). Cuando uno prueba algoritmos de clasificacion de imagenes, Mnist es bastante limitado, Cifar es un poco mas completo, el de ImageNet es el mejor (son los que le importa a la comunidad cientifica, es como el banco de pruebas). En general, los mejores modelos de CV para imagenet funcionan mejor que los humanos. Los humanos tienen un 94% de accuracy mientras que ImageNet tiene 96%.\n",
    "\n",
    "- Object detection: tenemos una imagen y queremos encontrar objetos en una imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificacion:\n",
    "\n",
    "Objetivo: Ver una imagen y clasificarla a una o n clases. \n",
    "\n",
    "Primer approach: extraccion de features o caracteristicas de una imagen. Dada una imagen la quiero convertir en un vector de features y una vez que tengo eso utilizo algun modelo de ML que ya conocemos, por ej random forest, xgboost, redes neuronales, cualquier algoritmo que funcione para multiclases. Como armo el vector? podemos agarrar cada bit y decir que uno vale el promedio del canal rojo, otro el promedio del canal verde, otro el promedio del canal azul, tambien se podria usar el maximo del rojo, el maximo del verde, el maximo del azul, la varianza de cada color.\n",
    "\n",
    "Features de imagenes:\n",
    "\n",
    "- Estadisticos: promedios, maximos, desviacion estandar.\n",
    "- Puntos: cuales son los puntos mas importantes de una imagen, no tomar el valor del pixel sino un descriptor que me descirba esos puntos. para eso se puede usar SIFT que genera descritpores de 128 bytes para cada punto clave de la imagen. La deteccion de putnos clave la hace con el algoritmo de SIFT. Este algoritmo hasta el 2020 estaba bajo un tema de patente, a partir de ahi expiro y se conviritio en libre de usar. SIFT se usa por ejemplo en construccion de imagenes panoramicas. Lo que hace SIFT es obtiene los mismos descriptores de dos imagenes distitnas que comparten algo y luego los une en el punto que se unen. Por ejemplo una montania divida en dos partes agarra los descriptores de un lado y del otro y la parte que es igual la une.\n",
    "- Filtros: Nos interesan un poco mas, miramos la operacion de convolusion. La idea es tener un filtro de tamanio mejor que la imagen.\n",
    "10  5   2   10  20              1       1       1\n",
    "5   0   0   3   2               1       1       1\n",
    "20  25  24  25  20              1       1       1\n",
    "1   2   0   0   1\n",
    "10  15  20  25  20\n",
    "\n",
    "la convolucion de estas matrices me queda:\n",
    "\n",
    "71  94  108\n",
    "77  79  75\n",
    "117 126 135\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "10  5   2   10  20              -1      -2      -1\n",
    "5   0   0   3   2                0       0       0\n",
    "20  25  24  25  20               1       2       1\n",
    "1   2   0   0   1\n",
    "10  15  20  25  20                              \n",
    "\n",
    "La convolucion de estas matrices me queda:\n",
    "\n",
    "72   79    52\n",
    "0    -1    -7\n",
    "-34  -18   -4\n",
    "\n",
    "\n",
    "20  20  20  20                  -1      -2      -1\n",
    "20  20  20  20                   0       0       0\n",
    "0   0   0   0                    1       2       1\n",
    "0   0   0   0\n",
    "\n",
    "La convolucion de estas matrices queda:\n",
    "\n",
    "-80     -80\n",
    "-80     -80\n",
    "\n",
    "\n",
    "20  20  20  20                   -1     -2      -1\n",
    "20  20  20  20                    0      0       0\n",
    "20  20  20  20                    1      2       1\n",
    "20  20  20  20\n",
    "\n",
    "la convolucion me queda:\n",
    "\n",
    "0       0\n",
    "0       0\n",
    "\n",
    "20  20  0   0                   -1      -2      -1\n",
    "20  20  0   0                    0       0       0      \n",
    "20  20  0   0                    1       2       1\n",
    "20  20  0   0\n",
    "\n",
    "la convolucion me queda:\n",
    "\n",
    "0       0\n",
    "0       0\n",
    "\n",
    "cuando tenemos una division de numeros tenemos un borde\n",
    "\n",
    "\n",
    "0   0   20  20                  -1      0       1\n",
    "0   0   20  20                  -2      0       2\n",
    "0   0   20  20                  -1      0       1\n",
    "0   0   20  20\n",
    "\n",
    "la convolucion me queda:\n",
    "\n",
    "80     80\n",
    "80     80\n",
    "\n",
    "0   0   0   0                   \n",
    "0   0   0   0\n",
    "20  20  20  20\n",
    "20  20  20  20\n",
    "\n",
    "80  80\n",
    "\n",
    "80  80\n",
    "\n",
    "\n",
    "\n",
    "sobel filter sirve para encontrar los 4 bordes posibles, horizontal vertical, etc\n",
    "\n",
    "-1  -2  -1                  1   2   1\n",
    "0   0   0                   0   0   0\n",
    "1   2   1                   -1  -2  -1\n",
    "\n",
    "-1  0   1                   1   0   -1  \n",
    "-2  0   2                   2   0   -2\n",
    "-1  0   1                   1   0   -1\n",
    "\n",
    "\n",
    "hay cientos de estos filtros.\n",
    "\n",
    "Porque no aplicar NNs? el prblema esta en la capa input, habria que hacer cada pixel con cada neurona lo que hace imposible la computabilidad, explota la cantidad de parametros lo que terminaria en overfitting.\n",
    "\n",
    "Cuando emepzo a funcionar? cuando aparecieron las redes convolucionales. Son las mas importantes paa clasificacion de imagenes.\n",
    "\n",
    "La idea de las redes convolucionales es simple pero fue una revolucion, hasta que aparecerion lo unico que funcionaba era extraer los features y armar un estadistico gigante. Esto se llama el problema de representacion. Las redes resuelven el problema de repsresntacion y nos permiten represtnar la imagen en crudo. Tomamos la imagen en crudo y los filtros los aprende la red, ese es el gran truco. En lugar de decirle aca voy a tener este filtro o este otro, la red directamente aprende cual es el filtro que se necesitan para hacer eso. Eso es una CNN. Las redes convolucionales empiezan con uno o mas filtros de convolucion en una imagen que esta en crudo. La funcion final aplicada es una softmax porque es un problema de multiclase.\n",
    "\n",
    "Capas convolucionales (conv 2D)\n",
    "\n",
    "input: n x n x c (imagen de n x n) (c = cantidad de canales)\n",
    "\n",
    "output: piso(((w - k + 2*p) / S)) + 1\n",
    "w = width\n",
    "K = filter size\n",
    "P = padding\n",
    "S = Stride\n",
    "\n",
    "Hiperparametos: \n",
    "\n",
    "- Tamanio del filtro: k (k * k * c)\n",
    "- Cantidad de filtros: f (cuantos filtros hay que encontrar)\n",
    "- Padding: tiene que ver con si quiero paddear la imagen, padding es agregarle un borde a la imagen con ceros. Dos opciones: o no usar padding, o usar same.\n",
    "- Stride: Cuantos pixeles voy desplazando a la convolucion, es decir cuando multiplico por el filtro la matriz me muevo dependiendo del valor de S, esto va a cambiar la dimension de salida de la matriz, nos podemos mover de a 1, 2, 3.. etc pixeles por la imagen.\n",
    "- Dilation: \n",
    "\n",
    "Si tengo una imagen de 5 x 5 y le aplico una convolucion de 2 x 2 el resultado me queda de 4 x 4, si le aplico una de 3 x 3 me queda de 3 x 3, si le aplico una de 4 x 4 me queda de 2 x 2, si es de 5 x 5 me queda de 1 x 1. la formula entonces si el input es n x n x c y el filtro es de k x k x c el output es: piso(((w - k + 2*p) / S)) + 1\n",
    "\n",
    "\n",
    "suponemos que tenemos una imagen de 200 x 200 x 3 le aplico una conv 2D con k = 5, f = 16.\n",
    "\n",
    "El output de los filtros es 196 x 196 x 16. 196 viene de (200 - 5) + 1. y 16 es porque son 16 filtros.\n",
    "\n",
    "parametros: ((5 x 5 x 3) + 1) x 16. 5 x 5 x 3 es el tamanio del filtro y el +1 es el bias o termino independiente.\n",
    "\n",
    "Las convoluciones siempre tienen la misma profundidad que tenia la imagen original.\n",
    "\n",
    "si agrego el padding en vez de quedarme 196 x 196 x 16 me quedaria 200 x 200 x 16\n",
    "\n",
    "\n",
    "Una red neuronal para una clasificacion podria ser:\n",
    "\n",
    "input                       conv 2D (2D porque son imagenes, si fuese en video seria conv 3D)       conv 2D\n",
    "\n",
    "200 x 200 x 3               K = 5                                                                   k = 3\n",
    "                            F = 16      --------> 196 x 196 x 16 ------------------->               F = 32 -------------> 194 x 194 x 32\n",
    "                            S = 1                                                                   S = 1   \n",
    "                            padding = none                                                          padding = none\n",
    "                            params:                                                                 params:\n",
    "                             ((5 x 5 x 3) + 1) * 16                                                 ((3 x 3 x 16) + 1) x 32\n",
    "\n",
    "\n",
    "capas max pooling \n",
    "\n",
    "20  20  10  0\n",
    "0   10  5   0           maxpool 2 x 2       --->    20  10\n",
    "2   4   -1  -2                                      6    3  ------> queda la dimensionalidad a la mitad\n",
    "6   4   3   1\n",
    "\n",
    "4 x 4\n",
    "\n",
    "por ejemplo si le aplico max pool a 194 x 194 x 32 me queda 97 x 97 x 32.\n",
    "\n",
    "en la capa de max pool tiene que aprender 0 parametros ya que no agregan parametros.\n",
    "\n",
    "ahora si a 97 x 97 le aplico una conv 2D con k = 10, F = 6, stride = 2, pading = none, sale de output: 44 x 44 x 6, y la cantidad de params = ((10 x 10 x 32) + 1) x 6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer CNN\n",
    "\n",
    "LeNet-5 (para MNIST):\n",
    "\n",
    "- Input: imagenes de 32x32x1 porque estan en blanco y negro, cada pixel es blanco o negro.\n",
    "\n",
    "CAPAS                     OUTPUT            PARAMS\n",
    "\n",
    "conv2D 5x5 (6)            28x28x6          (5x5 + 1) x 6\n",
    "\n",
    "avgPOOL                   14x14x6           ninguno para aprender (solo toma el promedio)\n",
    "\n",
    "conv2D 5x5 (16)           10x10x16          (5x5x6 + 1) x 16\n",
    "\n",
    "avgPOOL                   5x5x16            ninguno para aprender (solo toma el promedio)\n",
    "\n",
    "conv2D 1x1 (120)          5x5x120           (1x1x16 + 1) x120\n",
    "\n",
    "densa 120                   120                120x400 + 120\n",
    "\n",
    "densa 84                    84                  120x84 + 84\n",
    "\n",
    "softmax 10                  10                  10x84 + 10\n",
    "\n",
    "en LeNet-5 las conv2D usan como funcion de activacion la tangete hiperbolica, asi como se usa ReLU para otros algos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG-16 (una de las redes mas tipicas de computer vision)\n",
    "\n",
    "Basicamente se entrena con ImageNet, y la salida puede ser cualquier cosa.\n",
    "\n",
    "input: 224x224x3, ese es el tamanio de las imagenes que tienen en VGG-16, si no es de ese tamanio se hace un rezising\n",
    "\n",
    "params = 0\n",
    "\n",
    "CAPA                                                          OUTPUT                  params\n",
    "\n",
    "conv2D 3x3 (64), padding=\"same\", funcion de act=relu          224x224x64              ((3x3x3) + 1) x 64 += 1792\n",
    "\n",
    "conv2D 3x3 (64), padding=\"same\", funcion de act=relu          224x224x64              ((3x3x64) + 1) x 64 += 36928\n",
    "\n",
    "maxPOOL                                                       112x112x64                ninguno\n",
    "\n",
    "conv2D 3x3 (128), same, relu                                  112x112x128              ((3x3x64) + 1) x 128 += 73856\n",
    "\n",
    "conv2D 3x3 (128)   \"\"   \"\"                                    112X112X128               147584\n",
    "\n",
    "maxPOOl            \"\"   \"\"                                    56x56x128                     ninguno\n",
    "\n",
    "3x3 (256)           \"\"  \"\"                                    56x56x256                 295168\n",
    "\n",
    "3x3 (256)           \"\"  \"\"                                    56x56x256                 590080\n",
    "\n",
    "3x3 (256)           \"\"  \"\"                                    56x56x256                 590080\n",
    "\n",
    "maxpool             \"\"  \"\"                                    28x28x256                 ninguno\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    28x28x512                 1180160\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    28x28x512                 2359808\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    28x28x512                 2359808\n",
    "\n",
    "maxpool             \"\"  \"\"                                    14x14x512                 ninguno\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    14x14x512                 2359808\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    14x14x512                 2359808\n",
    "\n",
    "3x3 (512)           \"\"  \"\"                                    14x14x512                 2359808\n",
    "\n",
    "maxpool             \"\"  \"\"                                    7x7x512                   ninguno\n",
    "\n",
    "flatten             \"\"  \"\"                                    1x25088\n",
    "\n",
    "densa 4096          \"\"  \"\"                                    1x4096                    4096x35039 = 102764544\n",
    "\n",
    "densa 4096          \"\"  \"\"                                    1x4096                    4096x4097 = 16781312\n",
    "\n",
    "softmax\n",
    "\n",
    "params = 224 millones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection\n",
    "\n",
    "la idea es: dada una imagen que me diga lo que hay. Encontrar las cosas que hay en una imagen, se pueden encontrar distintos objetos que son de distintas claes y ademas decirte en donde esta el objeto.\n",
    "\n",
    "YOLO (\"You only look once\") (va por la version 8 (2023))\n",
    "\n",
    "vamos a ver la v1 (2015), es la que sento las bases y luego se fue mejorando\n",
    "\n",
    "convenciones: \n",
    "\n",
    "yolo va a definir un bounding box con cuatro numeros que son el centro y el ancho, cx, cy, wx, wy y todos estos van a estar entre 0 y 1. esto hace qe los bounding boxes sean independientes del tamanio de la imagen.\n",
    "\n",
    "yolo tambien va a definir la probabilidad de deteccion (p) que va a ser un numero entre 0 y 1 tambien.\n",
    "\n",
    "yolo tambien va a definir la probabilidad de cada clase (pc1 (car), pc2 (person), pc3 (etc)..., pcm)\n",
    "\n",
    "los 4 numeros del bounding box, la proba de deteccion y la proba de cada clase es el vector de salida del yolo , es el y del yolo. \n",
    "\n",
    "yolo lo que hace es la imagen dividirla en una grilla de sxs y cada una de esas grillas tiene uno de esos vectores asociados. para yolo v1 la grilla es de 7x7 y las clases son 10. solo podia detectar 10 clases entonces el vector de salida es de 7x7x(5 + 10)x2 = 7x7x30. el 2 es porque hay 2 boundig boxes por cada grilla. El gran truco de Yolo es que es un regresor no hay funcion de activacion en la capa final, son todos numeros que van entre 0 y 1, al ser un regresor va a entrenar y predecir super rapido. entonces es importante saber que yolo es un regresor. para entrenarlo hay que darle por cada imagen el vector de 7x7x30. cuando P es 0, yolo todo lo demas lo ignora, la funcion de loss de yolo es una funcion partida que depende de P, cuando P es 1 calcula el loss para todo los demas (pc1, pc2, etc..)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
