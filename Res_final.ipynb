{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Verdadero o Falso con ju\n",
    "\n",
    "a) Logistic Regression no puede usarse para problemas de clasificación multi-clase: puede ser verdadero o falso depende de como justifiques.\n",
    "\n",
    "b) Usar “leaky relu” en lugar de “relu” puede solucionar el problema del desvanecimiento del gradiente. verdadero: porque hay menos ceros que la relu comun\n",
    "\n",
    "c) Si nuestro problema es que tenemos mala accuracy en el set de train entonces estamos ante un problema de overfitting. Falso: deberiamos tener buen accuracy en el set de train y malo en el de testing.\n",
    "\n",
    "d) Si usamos Random Forests el principal parámetro para controlar overfitting es la cantidad de árboles en total. Falso, es el max_depth de cada arbol\n",
    "\n",
    "e) Usar una función de activación tipo Relu para una capa convolucional tiene más sentido si no hay capas de pooling. Verdadero\n",
    "\n",
    "f) KNN no puede usarse para problemas de clasificación multi-clase. Falso: De los n vecinos mas cercanos tomas la clase que mas aparece\n",
    "\n",
    "g) Agregar capas densas puede solucionar problemas de unerfitting en una red neuronal. Verdadero: agrega mas parametros, mas complejidad de modelo.\n",
    "\n",
    "h) Aumentar el tamaño del set de test ayudar a reducir overfitting. Falso: el set de test no tiene nada que ver con el de entrenamiento.\n",
    "\n",
    "2- cualquier cosa que no cambie el orden es neutro en los arboles\n",
    "\n",
    "a) No, mantiene el orden\n",
    "\n",
    "b) Si\n",
    "\n",
    "c) No, mantiene el orden\n",
    "\n",
    "d) Si\n",
    "\n",
    "3- tneer en cuenta que al final tiene que haber una softmax de 3 porque tenemos 3 posibles resultados, horizontal, vertical o ninguno.\n",
    "\n",
    "8x8x1\n",
    "\n",
    "Conv2D  3x3 (5) padding=same    output: 8x8x5\n",
    "maxpool                         output: 4x4x5\n",
    "flatten\n",
    "densa   \n",
    "softmax 3\n",
    "\n",
    "\n",
    "4- probar y ver cual arbol es mejor\n",
    "\n",
    "5- No se puede porque no tiene pendiente. El problema es que cuando esta mal no tenes forma de ajustar porque no tiene gradiente.\n",
    "\n",
    "6.3- lo que importa aca es ver el input y el output en este caso tneemos imagnees de 32x32 a color y una funcion sigmoid como output es decir un clasificador binario.\n",
    "\n",
    "7-\n",
    "\n",
    "Podria ser varias sigmoid por ejemplo\n",
    "\n",
    "O una sola softmax\n",
    "\n",
    "10-\n",
    "\n",
    "a) Verdadero, a medida que tenes mas dimensiones es mas porbable que las cosas sean linealmente separables\n",
    "\n",
    "b) Verdadero.\n",
    "\n",
    "c) Falso.\n",
    "\n",
    "d) Verdadero. Logisitc regression en general no es una muy buena idea salgo que el dataset sea muy angosto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- \n",
    "\n",
    "a) Falso, overfitting.\n",
    "\n",
    "b) Falso, overfitting. \n",
    "\n",
    "c) Falso\n",
    "\n",
    "d) Verdadero\n",
    "\n",
    "e) Verdadero\n",
    "\n",
    "f) Falso\n",
    "\n",
    "g) Falso\n",
    "\n",
    "4- podemos graficar y ver si sirve\n",
    "\n",
    "a) pareceria que sirve como funcion de activacion\n",
    "\n",
    "b) no, es lineal\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
